{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorirozen/AI_Tasks/blob/main/NlpTask3_Dori_Shlomi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSC_j4cmag28",
        "outputId": "ff87b698-f7ce-48f5-8873-a672c39e31d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#@title pips & imports\n",
        "!pip install -q beautifulsoup4 transformers sumy tensorflow keras torch datasets\n",
        "import nltk,time,spacy,csv,requests\n",
        "from bs4 import BeautifulSoup\n",
        "import transformers\n",
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, LSTM\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from pandas import unique\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
        "import re\n",
        "\n",
        "# Ensure you have the necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title BeautifulSoup part - We changed the URLs of the corpus source due to a large number of duplicate sentences that made the data very poor quality before we even started coding.\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "class WikiScraper:\n",
        "    def __init__(self):\n",
        "        self.domain = \"https://en.wikipedia.org/wiki/\"\n",
        "        self.sentences = []\n",
        "\n",
        "    def scrape_wikipedia(self, subject):\n",
        "        print(f\"üåê Scraping Wikipedia for '{subject}'...\")\n",
        "        url = f'{self.domain}{subject.replace(\" \", \"_\")}'\n",
        "        self.sentences = []\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()  # Check if the request was successful\n",
        "        except requests.RequestException as e:\n",
        "            print(f\"Error fetching the Wikipedia page: {e}\")\n",
        "            return\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        content = soup.find('div', {'id': 'mw-content-text'})\n",
        "        if content:\n",
        "            for element in content.find_all(['p', 'li']):\n",
        "                text = element.get_text().strip()\n",
        "                if text:  # Only append non-empty strings\n",
        "                    self.sentences.append(text)\n",
        "\n",
        "        if not self.sentences:\n",
        "            print(f\"No content found for {subject}\")\n",
        "\n",
        "    def save_to_file(self, filename):\n",
        "        print(f\"\\nüíæ Saving data to file...\")\n",
        "        with open(f'{filename}.txt', 'w', encoding='utf-8') as file:\n",
        "            for sentence in self.sentences:\n",
        "                file.write(sentence + '\\n')\n",
        "        print(f\"Data saved to {filename}.txt\")\n",
        "\n",
        "    def load_from_file(self, filename):\n",
        "        try:\n",
        "            print(f\"\\nüìÇ Loading data from file...\")\n",
        "            with open(f'{filename}.txt', 'r', encoding='utf-8') as file:\n",
        "                self.sentences = file.readlines()\n",
        "            self.sentences = [sentence.strip() for sentence in self.sentences]\n",
        "            print(f\"Data loaded from {filename}.txt\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File {filename}.txt not found.\")\n",
        "\n",
        "    def get_sentences(self):\n",
        "        return self.sentences\n",
        "\n",
        "    def print_stats(self):\n",
        "        print(f\"üìä Scraping Statistics:\")\n",
        "        print(f\"   Total sentences: {len(self.sentences)}\")\n",
        "        print(\"\\nüìú First 10 sentences (truncated to 100 characters):\")\n",
        "        for i, sentence in enumerate(self.sentences[:10], 1):\n",
        "            print(f\"   {i}. {sentence[:100]}...\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DhzWOwFgofFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWnnK1lNcDaH",
        "outputId": "10f127eb-df29-4e50-b9d0-c6ad4a00e418",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Scraping Wikipedia for 'Python_(programming_language)'...\n",
            "\n",
            "üíæ Saving data to file...\n",
            "Data saved to python_corpus.txt\n",
            "\n",
            "üìÇ Loading data from file...\n",
            "Data loaded from python_corpus.txt\n",
            "‚úÖ Scraping complete!\n",
            "üìä Scraping Statistics:\n",
            "   Total sentences: 955\n",
            "\n",
            "üìú First 10 sentences (truncated to 100 characters):\n",
            "   1. Python Programming at Wikibooks...\n",
            "   2. Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code ...\n",
            "   3. Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, inclu...\n",
            "   4. Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming lan...\n",
            "   5. Python consistently ranks as one of the most popular programming languages, and has gained widesprea...\n",
            "   6. Python was invented in the late 1980s[42] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI...\n",
            "   7. Python 2.0 was released on 16 October 2000, with many major new features such as list comprehensions...\n",
            "   8. Python 2.7's end-of-life was initially set for 2015, then postponed to 2020 out of concern that a la...\n",
            "   9. In 2021 (and again twice in 2022), security updates were expedited, since all Python versions were i...\n",
            "   10. As of October¬†2023,[update] Python 3.12 is the stable release, and 3.12 and 3.11 are the only versio...\n"
          ]
        }
      ],
      "source": [
        "#@title Our new corpus data\n",
        "scraper = WikiScraper()\n",
        "\n",
        "# Scrape Wikipedia\n",
        "subject = \"Python_(programming_language)\"\n",
        "\n",
        "scraper.scrape_wikipedia(subject)\n",
        "\n",
        "filename = \"python_corpus\"\n",
        "scraper.save_to_file(filename)\n",
        "scraper.load_from_file(filename)\n",
        "sentences = scraper.get_sentences()\n",
        "print(f\"‚úÖ Scraping complete!\")\n",
        "scraper.print_stats()\n",
        "\n",
        "CORPUS_PATH = f'/content/{filename}.txt'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F9AX2wybNZG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title TextPreprocessor\n",
        "\n",
        "class TextPreprocessor:\n",
        "    def __init__(self, options):\n",
        "        self.options = options\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        if 'lowercase' in self.options:\n",
        "            text = self._lowercase(text)\n",
        "        if 'normalize' in self.options:\n",
        "            text = self._normalize(text)\n",
        "        if 'tokenize_sentence' in self.options:\n",
        "            text = self._tokenize_sentence(text)\n",
        "        if 'tokenize_word' in self.options:\n",
        "            text = self._tokenize_word(text)\n",
        "        if 'regex_tokenize' in self.options:\n",
        "            text = self._regex_tokenize(text)\n",
        "        if 'whitespace_tokenize' in self.options:\n",
        "            text = self._whitespace_tokenize(text)\n",
        "        if 'remove_stopwords' in self.options:\n",
        "            text = self._remove_stopwords(text)\n",
        "        if 'lemmatize' in self.options:\n",
        "            text = self._lemmatize(text)\n",
        "        if 'stem' in self.options:\n",
        "            text = self._stem(text)\n",
        "        return text\n",
        "\n",
        "    def _lowercase(self, text):\n",
        "        return text.lower()\n",
        "\n",
        "    def _normalize(self, text):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove punctuation\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        # Normalize whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "\n",
        "    def _tokenize_sentence(self, text):\n",
        "        return sent_tokenize(text)\n",
        "\n",
        "    def _tokenize_word(self, text):\n",
        "        return word_tokenize(text)\n",
        "\n",
        "    def _regex_tokenize(self, text):\n",
        "        tokenizer = RegexpTokenizer(r'\\w+')\n",
        "        return tokenizer.tokenize(text)\n",
        "\n",
        "    def _whitespace_tokenize(self, text):\n",
        "        return text.split()\n",
        "\n",
        "    def _remove_stopwords(self, text):\n",
        "        if isinstance(text, list):\n",
        "            return [word for word in text if word.lower() not in self.stop_words]\n",
        "        else:\n",
        "            words = word_tokenize(text)\n",
        "            return ' '.join([word for word in words if word.lower() not in self.stop_words])\n",
        "\n",
        "    def _lemmatize(self, text):\n",
        "        if isinstance(text, list):\n",
        "            return [self.lemmatizer.lemmatize(word) for word in text]\n",
        "        else:\n",
        "            words = word_tokenize(text)\n",
        "            return ' '.join([self.lemmatizer.lemmatize(word) for word in words])\n",
        "\n",
        "    def _stem(self, text):\n",
        "        if isinstance(text, list):\n",
        "            return [self.stemmer.stem(word) for word in text]\n",
        "        else:\n",
        "            words = word_tokenize(text)\n",
        "            return ' '.join([self.stemmer.stem(word) for word in words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzEyWX38dFj9",
        "outputId": "e83d894a-b5bb-4dbb-b022-6e9fdc4415f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentences size: 955\n",
            "\n",
            "original sentences\n",
            "['Python Programming at Wikibooks', 'Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.[33]', 'Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.[34][35]', 'Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python\\xa00.9.0.[36] Python\\xa02.0 was released in 2000. Python\\xa03.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python\\xa02.7.18, released in 2020, was the last release of Python\\xa02.[37]', 'Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.[38][39][40][41]']\n",
            "\n",
            "\n",
            "processed sentences\n",
            "[['python', 'programming', 'wikibooks'], ['python', 'highlevel', 'generalpurpose', 'programming', 'language', 'design', 'philosophy', 'emphasizes', 'code', 'readability', 'use', 'significant', 'indentation33'], ['python', 'dynamically', 'typed', 'garbagecollected', 'support', 'multiple', 'programming', 'paradigm', 'including', 'structured', 'particularly', 'procedural', 'objectoriented', 'functional', 'programming', 'often', 'described', 'battery', 'included', 'language', 'due', 'comprehensive', 'standard', 'library3435'], ['guido', 'van', 'rossum', 'began', 'working', 'python', 'late', '1980s', 'successor', 'abc', 'programming', 'language', 'first', 'released', '1991', 'python', '09036', 'python', '20', 'released', '2000', 'python', '30', 'released', '2008', 'major', 'revision', 'completely', 'backwardcompatible', 'earlier', 'version', 'python', '2718', 'released', '2020', 'last', 'release', 'python', '237'], ['python', 'consistently', 'rank', 'one', 'popular', 'programming', 'language', 'gained', 'widespread', 'use', 'machine', 'learning', 'community38394041']]\n"
          ]
        }
      ],
      "source": [
        "options = [\n",
        "    'lowercase',\n",
        "    'normalize',\n",
        "    'tokenize_word',\n",
        "    'remove_stopwords',\n",
        "    'lemmatize'\n",
        "]\n",
        "print(f\"sentences size: {len(sentences)}\\n\")\n",
        "preprocessor = TextPreprocessor(options)\n",
        "print(\"original sentences\")\n",
        "\n",
        "print(sentences[:5])\n",
        "\n",
        "processed_sentences = [preprocessor.preprocess(sentence) for sentence in sentences]\n",
        "print(\"\\n\")\n",
        "print(\"processed sentences\")\n",
        "print(processed_sentences[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oQMGZcJdHfn"
      },
      "source": [
        "# RNN model and predicting the probability of the next word in a sentence."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TextSequenceModel\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, SimpleRNN, Dense\n",
        "\n",
        "class TextSequenceModel:\n",
        "    def __init__(self, sentences, max_sentences=200, embedding_dim=32, rnn_units=16, epochs=50, rnn_type='LSTM'):\n",
        "        self.sentences = sentences[:max_sentences]\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.rnn_units = rnn_units\n",
        "        self.epochs = epochs\n",
        "        self.rnn_type = rnn_type\n",
        "        self.tokenizer = Tokenizer()\n",
        "        self.model = None\n",
        "        self.max_seq_length = None\n",
        "        self.input_sequences = None\n",
        "        self.target_words = None\n",
        "        self._prepare_data()\n",
        "        self._build_model()\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        self.tokenizer.fit_on_texts(self.sentences)\n",
        "        sequences = self.tokenizer.texts_to_sequences(self.sentences)\n",
        "\n",
        "        input_sequences = []\n",
        "        target_words = []\n",
        "        for seq in sequences:\n",
        "            for i in range(1, len(seq)):\n",
        "                input_sequences.append(seq[:i])\n",
        "                target_words.append(seq[i])\n",
        "\n",
        "        self.max_seq_length = max([len(seq) for seq in input_sequences])\n",
        "        self.input_sequences = pad_sequences(input_sequences, maxlen=self.max_seq_length)\n",
        "\n",
        "        self.input_sequences = np.array(self.input_sequences)\n",
        "        self.target_words = np.array(target_words)\n",
        "\n",
        "    def _build_model(self):\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Embedding(input_dim=len(self.tokenizer.word_index) + 1, output_dim=self.embedding_dim, input_length=self.max_seq_length))\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            self.model.add(LSTM(self.rnn_units))\n",
        "        elif self.rnn_type == 'SimpleRNN':\n",
        "            self.model.add(SimpleRNN(self.rnn_units))\n",
        "        else:\n",
        "            raise ValueError(\"rnn_type must be either 'LSTM' or 'SimpleRNN'\")\n",
        "        self.model.add(Dense(len(self.tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n",
        "        self.model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        history = self.model.fit(self.input_sequences, self.target_words, epochs=self.epochs, verbose=0)\n",
        "        return history\n",
        "\n",
        "    def predict_next_word(self, input_text):\n",
        "\n",
        "        input_sequence = self.tokenizer.texts_to_sequences([input_text])[0]\n",
        "        input_sequence = pad_sequences([input_sequence], maxlen=self.max_seq_length)\n",
        "        predicted_probabilities = self.model.predict(input_sequence)[0]\n",
        "\n",
        "\n",
        "        next_word_index = np.argmax(predicted_probabilities)\n",
        "\n",
        "        next_word = self.tokenizer.index_word[next_word_index]\n",
        "\n",
        "        probability = predicted_probabilities[next_word_index]\n",
        "\n",
        "        return next_word, probability\n",
        "\n",
        "    def predict_word_probability(self, input_text, next_word):\n",
        "\n",
        "        input_sequence = self.tokenizer.texts_to_sequences([input_text])[0]\n",
        "        input_sequence = pad_sequences([input_sequence], maxlen=self.max_seq_length)\n",
        "        predicted_probabilities = self.model.predict(input_sequence)[0]\n",
        "\n",
        "        next_word_index = self.tokenizer.word_index.get(next_word)\n",
        "\n",
        "        if next_word_index is None:\n",
        "            return 0.0\n",
        "\n",
        "\n",
        "        return predicted_probabilities[next_word_index]\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ST5JHL68zSS-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title training the models LSTM and RNN\n",
        "print(\"ü§ñ Text Sequence Model Training\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"üìä LSTM Model\")\n",
        "print(\"=\" * 80)\n",
        "sentences_slice = processed_sentences[240:400]\n",
        "lstm_model = TextSequenceModel(sentences_slice, rnn_type='LSTM')\n",
        "lstm_history = lstm_model.train()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"üìà SimpleRNN Model\")\n",
        "print(\"=\" * 80)\n",
        "sentences_slice = processed_sentences[240:400]\n",
        "\n",
        "rnn_model = TextSequenceModel(sentences_slice, rnn_type='SimpleRNN')\n",
        "rnn_history = rnn_model.train()\n",
        "\n",
        "print(\"‚úÖ Training complete!\")\n",
        "\n",
        "#@title Comparing the two\n",
        "print(\"=\" * 80)\n",
        "print(\"üîç Model Comparison\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nLSTM Model:\")\n",
        "print(f\"   Loss: {lstm_history.history['loss'][-1]:.4f}\")\n",
        "print(f\"   Accuracy: {lstm_history.history['accuracy'][-1]:.4f}\")\n",
        "\n",
        "print(f\"\\nSimpleRNN Model:\")\n",
        "print(f\"   Loss: {rnn_history.history['loss'][-1]:.4f}\")\n",
        "print(f\"   Accuracy: {rnn_history.history['accuracy'][-1]:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚úÖ Analysis complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruTc6YBI4KoK",
        "outputId": "f724a040-9860-4df9-dac5-09e2f42bdee5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Text Sequence Model Training\n",
            "\n",
            "================================================================================\n",
            "üìä LSTM Model\n",
            "================================================================================\n",
            "================================================================================\n",
            "üìà SimpleRNN Model\n",
            "================================================================================\n",
            "‚úÖ Training complete!\n",
            "================================================================================\n",
            "üîç Model Comparison\n",
            "================================================================================\n",
            "\n",
            "LSTM Model:\n",
            "   Loss: 3.6149\n",
            "   Accuracy: 0.2335\n",
            "\n",
            "SimpleRNN Model:\n",
            "   Loss: 2.6831\n",
            "   Accuracy: 0.3886\n",
            "\n",
            "================================================================================\n",
            "‚úÖ Analysis complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title print_model_predictions\n",
        "from textwrap import fill\n",
        "def print_model_predictions(model, model_name, input_sequence, specific_word):\n",
        "    print(\"ü§ñ Text Sequence Model Predictions\\n\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"üìä {model_name} Model\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    next_word, probability = model.predict_next_word(input_sequence)\n",
        "    print(\"\\nüîÆ Prediction:\")\n",
        "    print(f\"   Input: \\\"{input_sequence}\\\"\")\n",
        "    print(f\"   Next word: \\\"{next_word}\\\"\")\n",
        "    print(f\"   Probability: {probability:.4f}\")\n",
        "\n",
        "    specific_prob = model.predict_word_probability(input_sequence, specific_word)\n",
        "    print(f\"\\nüéØ Probability of specific word:\")\n",
        "    print(f\"   Word: \\\"{specific_word}\\\"\")\n",
        "    print(f\"   Probability: {specific_prob:.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
        "\n",
        "    if model_name == \"SimpleRNN\":\n",
        "        print(\"‚úÖ Predictions complete!\")\n",
        "\n",
        "\n",
        "input_sequence = \"I love\"\n",
        "specific_word = \"programming\"\n",
        "print_model_predictions(lstm_model, \"LSTM\", input_sequence, specific_word)\n",
        "print(\"=\" * 80)\n",
        "print_model_predictions(rnn_model, \"SimpleRNN\", input_sequence, specific_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2GMcwOY4w8_",
        "outputId": "42903ec1-9497-410d-9808-594c42ed1f15"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Text Sequence Model Predictions\n",
            "\n",
            "================================================================================\n",
            "üìä LSTM Model\n",
            "================================================================================\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "\n",
            "üîÆ Prediction:\n",
            "   Input: \"I love\"\n",
            "   Next word: \"software\"\n",
            "   Probability: 0.0571\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "\n",
            "üéØ Probability of specific word:\n",
            "   Word: \"programming\"\n",
            "   Probability: 0.0060\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "ü§ñ Text Sequence Model Predictions\n",
            "\n",
            "================================================================================\n",
            "üìä SimpleRNN Model\n",
            "================================================================================\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "\n",
            "üîÆ Prediction:\n",
            "   Input: \"I love\"\n",
            "   Next word: \"python\"\n",
            "   Probability: 0.0673\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "\n",
            "üéØ Probability of specific word:\n",
            "   Word: \"programming\"\n",
            "   Probability: 0.0059\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úÖ Predictions complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title KLSummarizer\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.kl import KLSummarizer\n",
        "from textwrap import fill\n",
        "\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "summarizer = KLSummarizer()\n",
        "\n",
        "print(\"üìö Sentence Summaries:\\n\")\n",
        "\n",
        "for i, sentence in enumerate(sentences[1:11], start=1):\n",
        "    parser = PlaintextParser.from_string(sentence, Tokenizer(\"english\"))\n",
        "    summary = summarizer(parser.document, 1)\n",
        "\n",
        "    print(f\"{'=' * 80}\")\n",
        "    print(f\"üìå Sentence {i}\")\n",
        "    print(f\"{'=' * 80}\\n\")\n",
        "\n",
        "    print(\"üìú Original:\")\n",
        "    print(fill(sentence, width=80, initial_indent=\"   \", subsequent_indent=\"   \"))\n",
        "\n",
        "    print(\"\\nüí° Summary:\")\n",
        "    print(fill(str(summary[0]), width=80, initial_indent=\"   \", subsequent_indent=\"   \"))\n",
        "\n",
        "    print(f\"\\n{'-' * 80}\\n\")\n",
        "\n",
        "print(\"‚úÖ Summarization complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27McIoV2jtEX",
        "outputId": "9b5f9a7a-98d1-4c7d-c4c9-46f90b357b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö Sentence Summaries:\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 1\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python is a high-level, general-purpose programming language. Its design\n",
            "   philosophy emphasizes code readability with the use of significant\n",
            "   indentation.[33]\n",
            "\n",
            "üí° Summary:\n",
            "   Python is a high-level, general-purpose programming language.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 2\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python is dynamically typed and garbage-collected. It supports multiple\n",
            "   programming paradigms, including structured (particularly procedural),\n",
            "   object-oriented and functional programming. It is often described as a\n",
            "   \"batteries included\" language due to its comprehensive standard\n",
            "   library.[34][35]\n",
            "\n",
            "üí° Summary:\n",
            "   It supports multiple programming paradigms, including structured\n",
            "   (particularly procedural), object-oriented and functional programming.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 3\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Guido van Rossum began working on Python in the late 1980s as a successor to\n",
            "   the ABC programming language and first released it in 1991 as\n",
            "   Python¬†0.9.0.[36] Python¬†2.0 was released in 2000. Python¬†3.0, released in\n",
            "   2008, was a major revision not completely backward-compatible with earlier\n",
            "   versions. Python¬†2.7.18, released in 2020, was the last release of\n",
            "   Python¬†2.[37]\n",
            "\n",
            "üí° Summary:\n",
            "   [36] Python¬†2.0 was released in 2000.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 4\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python consistently ranks as one of the most popular programming languages,\n",
            "   and has gained widespread use in the machine learning\n",
            "   community.[38][39][40][41]\n",
            "\n",
            "üí° Summary:\n",
            "   Python consistently ranks as one of the most popular programming languages,\n",
            "   and has gained widespread use in the machine learning community.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 5\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python was invented in the late 1980s[42] by Guido van Rossum at Centrum\n",
            "   Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC\n",
            "   programming language, which was inspired by SETL,[43] capable of exception\n",
            "   handling and interfacing with the Amoeba operating system.[12] Its\n",
            "   implementation began in December¬†1989.[44] Van Rossum shouldered sole\n",
            "   responsibility for the project, as the lead developer, until 12 July 2018,\n",
            "   when he announced his \"permanent vacation\" from his responsibilities as\n",
            "   Python's \"benevolent dictator for life\" (BDFL), a title the Python community\n",
            "   bestowed upon him to reflect his long-term commitment as the project's chief\n",
            "   decision-maker[45] (he's since come out of retirement and is self-titled\n",
            "   \"BDFL-emeritus\"). In January¬†2019, active Python core developers elected a\n",
            "   five-member Steering Council to lead the project.[46][47]\n",
            "\n",
            "üí° Summary:\n",
            "   Python was invented in the late 1980s[42] by Guido van Rossum at Centrum\n",
            "   Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC\n",
            "   programming language, which was inspired by SETL,[43] capable of exception\n",
            "   handling and interfacing with the Amoeba operating system.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 6\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python 2.0 was released on 16 October 2000, with many major new features such\n",
            "   as list comprehensions, cycle-detecting garbage collection, reference\n",
            "   counting, and Unicode support.[48] Python¬†3.0, released on 3 December 2008,\n",
            "   with many of its major features backported to Python¬†2.6.x[49] and 2.7.x.\n",
            "   Releases of Python¬†3 include the 2to3 utility, which automates the\n",
            "   translation of Python¬†2 code to Python¬†3.[50]\n",
            "\n",
            "üí° Summary:\n",
            "   Releases of Python¬†3 include the 2to3 utility, which automates the\n",
            "   translation of Python¬†2 code to Python¬†3.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 7\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python 2.7's end-of-life was initially set for 2015, then postponed to 2020\n",
            "   out of concern that a large body of existing code could not easily be\n",
            "   forward-ported to Python¬†3.[51][52] No further security patches or other\n",
            "   improvements will be released for it.[53][54] Currently only 3.8 and later\n",
            "   are supported (2023 security issues were fixed in e.g. 3.7.17, the final\n",
            "   3.7.x release[55]). While Python 2.7 and older is officially unsupported, a\n",
            "   different unofficial Python implementation, PyPy, continues to support Python\n",
            "   2, i.e. \"2.7.18+\" (plus 3.9 and 3.10), with the plus meaning (at least some)\n",
            "   \"backported security updates\".[56]\n",
            "\n",
            "üí° Summary:\n",
            "   Python 2.7's end-of-life was initially set for 2015, then postponed to 2020\n",
            "   out of concern that a large body of existing code could not easily be\n",
            "   forward-ported to Python¬†3.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 8\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   In 2021 (and again twice in 2022), security updates were expedited, since all\n",
            "   Python versions were insecure (including 2.7[57]) because of security issues\n",
            "   leading to possible remote code execution[58] and web-cache poisoning.[59] In\n",
            "   2022, Python¬†3.10.4 and 3.9.12 were expedited[60] and 3.8.13, because of many\n",
            "   security issues.[61] When Python¬†3.9.13 was released in May 2022, it was\n",
            "   announced that the 3.9 series (joining the older series 3.8 and 3.7) would\n",
            "   only receive security fixes in the future.[62] On 7 September 2022, four new\n",
            "   releases were made due to a potential denial-of-service attack: 3.10.7,\n",
            "   3.9.14, 3.8.14, and 3.7.14.[63][64]\n",
            "\n",
            "üí° Summary:\n",
            "   [59] In 2022, Python¬†3.10.4 and 3.9.12 were expedited[60] and 3.8.13, because\n",
            "   of many security issues.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 9\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   As of October¬†2023,[update] Python 3.12 is the stable release, and 3.12 and\n",
            "   3.11 are the only versions with active (as opposed to just security) support.\n",
            "   Notable changes in 3.11 from 3.10 include increased program execution speed\n",
            "   and improved error reporting.[65]\n",
            "\n",
            "üí° Summary:\n",
            "   Notable changes in 3.11 from 3.10 include increased program execution speed\n",
            "   and improved error reporting.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 10\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Every Python release since 3.5 has added some syntax to the language. 3.10\n",
            "   added the | union type operator [66] and the match and case keywords (for\n",
            "   structural pattern matching statements). 3.11 expanded exception handling\n",
            "   functionality. Python 3.12 added the new keyword type.\n",
            "\n",
            "üí° Summary:\n",
            "   Python 3.12 added the new keyword type.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úÖ Summarization complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load pre-trained model and tokenizer\n",
        "import os\n",
        "import random\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import torch\n",
        "\n",
        "print(\"üìö Loading pre-trained model and tokenizer...\")\n",
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "hvMOQXF7q-A_",
        "outputId": "fc9a8090-250c-4133-b0de-db31d288f9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö Loading pre-trained model and tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Using the pre-trained model and his tokenizer for fine tune\n",
        "def load_dataset(file_path, tokenizer):\n",
        "    dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=file_path,\n",
        "        block_size=128)\n",
        "    return dataset\n",
        "\n",
        "print(\"üîç Preparing dataset...\")\n",
        "if not os.path.exists(CORPUS_PATH):\n",
        "    raise FileNotFoundError(f\"Corpus file not found: {CORPUS_PATH}\")\n",
        "train_dataset = load_dataset(CORPUS_PATH, tokenizer)\n",
        "\n",
        "print(\"üõ†Ô∏è Setting up training configuration...\")\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False,\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting fine-tuning process...\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"üíæ Saving the fine-tuned model...\")\n",
        "trainer.save_model()\n",
        "print(\"‚úÖ Fine-tuning complete. Model saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "okBcR-1IlaDF",
        "outputId": "b05db89d-3b6c-4263-8f2b-607182456800",
        "cellView": "form"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Preparing dataset...\n",
            "üõ†Ô∏è Setting up training configuration...\n",
            "üöÄ Starting fine-tuning process...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='88' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [88/88 14:50, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Saving the fine-tuned model...\n",
            "‚úÖ Fine-tuning complete. Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(prompt, max_length=100):\n",
        "    if not prompt.strip():\n",
        "        return \"Error: Empty prompt provided.\"\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"\\nü§ñ Text Generation from Partial Sentences\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "scraper.load_from_file(filename)\n",
        "corpus = scraper.get_sentences()\n",
        "\n",
        "# Filter out empty sentences\n",
        "corpus = [sentence for sentence in corpus if sentence.strip()]\n",
        "\n",
        "if not corpus:\n",
        "    print(\"‚ùå Error: No valid sentences found in the corpus.\")\n",
        "else:\n",
        "    partial_sentences = random.sample(corpus, min(5, len(corpus)))\n",
        "    partial_sentences = [' '.join(sentence.split()[:max(1, len(sentence.split())//2)]) for sentence in partial_sentences]\n",
        "\n",
        "    for i, partial in enumerate(partial_sentences, 1):\n",
        "        print(f\"\\nüìå Sample {i}\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        print(\"üîç Partial sentence:\")\n",
        "        print(f\"   {partial}\")\n",
        "\n",
        "        completion = generate_text(partial)\n",
        "\n",
        "        print(f\"\\n‚ú® Completion:\")\n",
        "        print(f\"   {completion}\")\n",
        "\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "print(\"\\n‚úÖ Text generation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d69Curyew2AY",
        "outputId": "3bcd27d7-bf12-4609-b2ad-3742c736afd9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ü§ñ Text Generation from Partial Sentences\n",
            "================================================================================\n",
            "\n",
            "üìÇ Loading data from file...\n",
            "Data loaded from python_corpus.txt\n",
            "\n",
            "üìå Sample 1\n",
            "================================================================================\n",
            "üîç Partial sentence:\n",
            "   Python provides a round function for rounding a float to the nearest integer. For tie-breaking, Python 3 uses round\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Completion:\n",
            "   Python provides a round function for rounding a float to the nearest integer. For tie-breaking, Python 3 uses round to find the smallest integer in the range from zero to infinity.\n",
            "^ The \"t\" in a decimal is a unit of the number from which the decimal point is assigned. When rounding, \"^\" is an integer, and \"e\" the \"E\" a \"number\". The difference between the two numbers is the rounding error in each case, as in which case the\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå Sample 2\n",
            "================================================================================\n",
            "üîç Partial sentence:\n",
            "   Machine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Completion:\n",
            "   Machine in Python\n",
            "Jasmine, the first open-source computer programming language, has now been released and has a large community, including many in the Python community. Jasmin (pronounced \"jas\", from the original). JASM is a community of software developers, software engineers, engineers and security specialists who build and maintain the software they use. It is also the home of Jaspi, a Java-like language and Web-based data science platform.\n",
            "The J\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå Sample 3\n",
            "================================================================================\n",
            "üîç Partial sentence:\n",
            "   ^ Esterbrook, Charles. \"Acknowledgements\". cobra-language.com. Cobra Language. Archived from\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Completion:\n",
            "   ^ Esterbrook, Charles. \"Acknowledgements\". cobra-language.com. Cobra Language. Archived from the original on 9 June 2020. Retrieved 5 May 2020.[9]\n",
            "^ \"An Introduction to Python\". Python.org. Python Software Foundation. CPAN.\n",
            "[10] \"PEP 318 - Introduction and Python 3.0.3\". peps.python.io. ppa.pepsi.opensource.pl. The python.cpython provides\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå Sample 4\n",
            "================================================================================\n",
            "üîç Partial sentence:\n",
            "   The if statement, which conditionally executes a block of\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚ú® Completion:\n",
            "   The if statement, which conditionally executes a block of code, e.g. if a function is called with a value of a certain value.\n",
            "^ back to top\n",
            "As a result of the above, a class is written as a variable named value, and a reference is made to it. The first part of an object is a list of values, and the third one is the name of that object. An object with an internal reference name can be used to create a new object (\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìå Sample 5\n",
            "================================================================================\n",
            "üîç Partial sentence:\n",
            "   Python's\n",
            "\n",
            "‚ú® Completion:\n",
            "   Python's C compiler was inspired by the Python programming language, which was used in many other languages, including Java, Python, and C#.\n",
            "The original syntax was borrowed from the original Python,[2] but was replaced with a more concise syntax.[3]\n",
            "An important change was to the underlying program:\n",
            "Python was a \"pure\" language,[4][5] and the syntax had a large influence on the development of other programs.[6] It also influenced many programmers, as well\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "‚úÖ Text generation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title SentimentIntensityAnalyzer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textwrap import fill\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_sentiment_emoji(score):\n",
        "    if score > 60:\n",
        "        return \"üòÉ\"\n",
        "    elif score < 40:\n",
        "        return \"üòî\"\n",
        "    else:\n",
        "        return \"üòê\"\n",
        "\n",
        "for i, sentence in enumerate(sentences[1:11], start=1):\n",
        "    print(\"ü§ñ Sentiment Analysis\")\n",
        "    print(\"=\" * 80)\n",
        "    sentiment_scores = sid.polarity_scores(sentence)\n",
        "\n",
        "    positive_sentiment = sentiment_scores['pos'] * 100\n",
        "    negative_sentiment = sentiment_scores['neg'] * 100\n",
        "    neutral_sentiment = sentiment_scores['neu'] * 100\n",
        "\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(f\"üìå Sentence {i}\")\n",
        "    print(f\"{'=' * 80}\")\n",
        "\n",
        "    print(\"\\nüìú Original:\")\n",
        "    print(fill(sentence, width=80, initial_indent=\"   \", subsequent_indent=\"   \"))\n",
        "\n",
        "    print(\"\\nüìä Sentiment Analysis Statistics:\")\n",
        "    print(f\"   {get_sentiment_emoji(positive_sentiment)} Positive: {positive_sentiment:.2f}%\")\n",
        "    print(f\"   {get_sentiment_emoji(negative_sentiment)} Negative: {negative_sentiment:.2f}%\")\n",
        "    print(f\"   {get_sentiment_emoji(neutral_sentiment)} Neutral:  {neutral_sentiment:.2f}%\")\n",
        "\n",
        "    print(f\"\\n{'-' * 80}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_NI-QtIiooa",
        "outputId": "dfb8580b-428f-4eb6-8af9-cd3813552e9a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 1\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python is a high-level, general-purpose programming language. Its design\n",
            "   philosophy emphasizes code readability with the use of significant\n",
            "   indentation.[33]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 9.60%\n",
            "   üòî Negative: 0.00%\n",
            "   üòÉ Neutral:  90.40%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 2\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python is dynamically typed and garbage-collected. It supports multiple\n",
            "   programming paradigms, including structured (particularly procedural),\n",
            "   object-oriented and functional programming. It is often described as a\n",
            "   \"batteries included\" language due to its comprehensive standard\n",
            "   library.[34][35]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 18.90%\n",
            "   üòî Negative: 0.00%\n",
            "   üòÉ Neutral:  81.10%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 3\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Guido van Rossum began working on Python in the late 1980s as a successor to\n",
            "   the ABC programming language and first released it in 1991 as\n",
            "   Python¬†0.9.0.[36] Python¬†2.0 was released in 2000. Python¬†3.0, released in\n",
            "   2008, was a major revision not completely backward-compatible with earlier\n",
            "   versions. Python¬†2.7.18, released in 2020, was the last release of\n",
            "   Python¬†2.[37]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 3.20%\n",
            "   üòî Negative: 0.00%\n",
            "   üòÉ Neutral:  96.80%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 4\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python consistently ranks as one of the most popular programming languages,\n",
            "   and has gained widespread use in the machine learning\n",
            "   community.[38][39][40][41]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 23.10%\n",
            "   üòî Negative: 0.00%\n",
            "   üòÉ Neutral:  76.90%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 5\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python was invented in the late 1980s[42] by Guido van Rossum at Centrum\n",
            "   Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC\n",
            "   programming language, which was inspired by SETL,[43] capable of exception\n",
            "   handling and interfacing with the Amoeba operating system.[12] Its\n",
            "   implementation began in December¬†1989.[44] Van Rossum shouldered sole\n",
            "   responsibility for the project, as the lead developer, until 12 July 2018,\n",
            "   when he announced his \"permanent vacation\" from his responsibilities as\n",
            "   Python's \"benevolent dictator for life\" (BDFL), a title the Python community\n",
            "   bestowed upon him to reflect his long-term commitment as the project's chief\n",
            "   decision-maker[45] (he's since come out of retirement and is self-titled\n",
            "   \"BDFL-emeritus\"). In January¬†2019, active Python core developers elected a\n",
            "   five-member Steering Council to lead the project.[46][47]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 12.60%\n",
            "   üòî Negative: 0.00%\n",
            "   üòÉ Neutral:  87.40%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 6\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python 2.0 was released on 16 October 2000, with many major new features such\n",
            "   as list comprehensions, cycle-detecting garbage collection, reference\n",
            "   counting, and Unicode support.[48] Python¬†3.0, released on 3 December 2008,\n",
            "   with many of its major features backported to Python¬†2.6.x[49] and 2.7.x.\n",
            "   Releases of Python¬†3 include the 2to3 utility, which automates the\n",
            "   translation of Python¬†2 code to Python¬†3.[50]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 0.00%\n",
            "   üòî Negative: 0.00%\n",
            "   üòÉ Neutral:  100.00%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 7\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Python 2.7's end-of-life was initially set for 2015, then postponed to 2020\n",
            "   out of concern that a large body of existing code could not easily be\n",
            "   forward-ported to Python¬†3.[51][52] No further security patches or other\n",
            "   improvements will be released for it.[53][54] Currently only 3.8 and later\n",
            "   are supported (2023 security issues were fixed in e.g. 3.7.17, the final\n",
            "   3.7.x release[55]). While Python 2.7 and older is officially unsupported, a\n",
            "   different unofficial Python implementation, PyPy, continues to support Python\n",
            "   2, i.e. \"2.7.18+\" (plus 3.9 and 3.10), with the plus meaning (at least some)\n",
            "   \"backported security updates\".[56]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 13.50%\n",
            "   üòî Negative: 8.10%\n",
            "   üòÉ Neutral:  78.30%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 8\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   In 2021 (and again twice in 2022), security updates were expedited, since all\n",
            "   Python versions were insecure (including 2.7[57]) because of security issues\n",
            "   leading to possible remote code execution[58] and web-cache poisoning.[59] In\n",
            "   2022, Python¬†3.10.4 and 3.9.12 were expedited[60] and 3.8.13, because of many\n",
            "   security issues.[61] When Python¬†3.9.13 was released in May 2022, it was\n",
            "   announced that the 3.9 series (joining the older series 3.8 and 3.7) would\n",
            "   only receive security fixes in the future.[62] On 7 September 2022, four new\n",
            "   releases were made due to a potential denial-of-service attack: 3.10.7,\n",
            "   3.9.14, 3.8.14, and 3.7.14.[63][64]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 9.20%\n",
            "   üòî Negative: 5.60%\n",
            "   üòÉ Neutral:  85.20%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 9\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   As of October¬†2023,[update] Python 3.12 is the stable release, and 3.12 and\n",
            "   3.11 are the only versions with active (as opposed to just security) support.\n",
            "   Notable changes in 3.11 from 3.10 include increased program execution speed\n",
            "   and improved error reporting.[65]\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 25.30%\n",
            "   üòî Negative: 5.30%\n",
            "   üòÉ Neutral:  69.30%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "ü§ñ Sentiment Analysis\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "üìå Sentence 10\n",
            "================================================================================\n",
            "\n",
            "üìú Original:\n",
            "   Every Python release since 3.5 has added some syntax to the language. 3.10\n",
            "   added the | union type operator [66] and the match and case keywords (for\n",
            "   structural pattern matching statements). 3.11 expanded exception handling\n",
            "   functionality. Python 3.12 added the new keyword type.\n",
            "\n",
            "üìä Sentiment Analysis Statistics:\n",
            "   üòî Positive: 0.00%\n",
            "   üòî Negative: 0.00%\n",
            "   üòÉ Neutral:  100.00%\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvWM2Zzm1wNdnvSw3odODC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}